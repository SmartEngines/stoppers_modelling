{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook contains the code for precalculating estimation values in order to further analyze them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, time\n",
    "import multiprocessing\n",
    "import pickle\n",
    "\n",
    "from metrics import *\n",
    "from combination import *\n",
    "from combination_with_estimation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET = 'midv500'\n",
    "DATASET = 'midv2019'\n",
    "\n",
    "FIELD_TYPES = ['docnum', 'date', 'latin', 'mrz']\n",
    "\n",
    "DATASET_DIRECTORIES = {\n",
    "    'docnum': './data_%s/docnum' % DATASET,\n",
    "    'date': './data_%s/date' % DATASET,\n",
    "    'latin': './data_%s/latin' % DATASET,\n",
    "    'mrz': './data_%s/mrz' % DATASET\n",
    "}\n",
    "\n",
    "METHODS = ['base', 'summation', 'treap']\n",
    "\n",
    "PRECALC_DIRECTORIES = {\n",
    "    'base': './precalc_base_%s' % DATASET,\n",
    "    'summation': './precalc_summation_%s' % DATASET,\n",
    "    'treap': './precalc_treap_%s' % DATASET\n",
    "}\n",
    "\n",
    "# creating precalc directories if there are none\n",
    "for method in METHODS:\n",
    "    if not os.path.exists(PRECALC_DIRECTORIES[method]):\n",
    "        os.mkdir(PRECALC_DIRECTORIES[method])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ocrstring(serialized_ocrstring):\n",
    "    '''\n",
    "    Converts a serialized text string recognition result to a list of Cells\n",
    "    '''\n",
    "    ret = []\n",
    "    for serialized_ocrcell in serialized_ocrstring:\n",
    "        varmap = serialized_ocrcell\n",
    "        if '@' not in varmap.keys():\n",
    "            varmap['@'] = 0.0\n",
    "        ret.append(Cell(varmap))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_clip(job):\n",
    "    pickled_data, method = job\n",
    "    '''\n",
    "    Precalculates modelling sums for each prefix of normalize clip (serialized as pickled_data) \n",
    "    using method 'method'. Outputs precalculating results in a newly generated JSON file in\n",
    "    the precalculating directory for this method\n",
    "    '''\n",
    "    # loading pickled clip\n",
    "    loaded_clip = None\n",
    "    with open(pickled_data, 'rb') as ps:\n",
    "        loaded_clip = pickle.load(ps)\n",
    "    \n",
    "    # converting text string recognition results and bringing clip to length 30\n",
    "    clip_strings = [convert_ocrstring(x) for x in (loaded_clip['clip'] * 30)[:30]]\n",
    "    \n",
    "    # precalculation results: [(error_level, modelling sum, time of combination, time of modelling)]\n",
    "    ret = [] \n",
    "        \n",
    "    alignment = None\n",
    "    if method == 'base':\n",
    "        alignment = Alignment(0.6)\n",
    "    elif method == 'summation':\n",
    "        alignment = AlignmentWithEstimation(0.6, ListBasedSequenceStructure)\n",
    "    elif method == 'treap':\n",
    "        alignment = AlignmentWithEstimation(0.6, TreapBasedSequenceStructure)\n",
    "    else:\n",
    "        raise Exception('unknown method %s' % method)\n",
    "        \n",
    "    for i_frame, frame_string in enumerate(clip_strings):\n",
    "        # combining frame_string with currently accumulated results\n",
    "        combination_start = 0\n",
    "        combination_end = 0\n",
    "        if method == 'base':\n",
    "            combination_start = time.time()\n",
    "            alignment.add_string(frame_string, 1.0)\n",
    "            combination_end = time.time()\n",
    "        else: # for this AlignmentWithEstimation implementation there are no input sample weights\n",
    "            combination_start = time.time()\n",
    "            alignment.add_string(frame_string)\n",
    "            combination_end = time.time()\n",
    "        \n",
    "        combined_result_string = alignment.get_string_result()\n",
    "        \n",
    "        modelling_sum = 0.0\n",
    "        modelling_start = 0\n",
    "        modelling_end = 0\n",
    "        if method == 'base':\n",
    "            modelling_start = time.time()\n",
    "            # computing the modelling sum directly by test-combining previous samples\n",
    "            for j_frame in range(i_frame + 1):\n",
    "                copied_alignment = alignment.clone()\n",
    "                copied_alignment.add_string(clip_strings[j_frame], 1.0)\n",
    "                modelling_sum += levmetric_ocr(copied_alignment.base, alignment.base)\n",
    "            modelling_end = time.time()\n",
    "        else:\n",
    "            modelling_start = time.time()\n",
    "            modelling_sum = alignment.get_modelling_sum()\n",
    "            modelling_end = time.time()\n",
    "        \n",
    "        ret.append((levmetric(combined_result_string, loaded_clip['ideal']), \\\n",
    "                    modelling_sum, \\\n",
    "                    combination_end - combination_start, \\\n",
    "                    modelling_end - modelling_start))\n",
    "    \n",
    "    output_filename = '%s_%s_%s_%s_precalc.json' % (loaded_clip['field_type'], \\\n",
    "                                                    loaded_clip['clip_id'], \\\n",
    "                                                    loaded_clip['field_name'], \\\n",
    "                                                    method)\n",
    "    \n",
    "    with open(os.path.join(PRECALC_DIRECTORIES[method], output_filename), 'w') as js:\n",
    "        js.write(json.dumps(ret, indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precalculate(field_types, method, parallel_processes):\n",
    "    '''\n",
    "    Runs precalculation for clips of types in 'field_types' list, using method 'method', \n",
    "    and using a certain number of parallel processes'\n",
    "    \n",
    "    It needs to be run with parallel_processes = 1 if time measurement have to be obtained.\n",
    "    '''\n",
    "    datafiles = []\n",
    "    for field_type in field_types:\n",
    "        dataset_directory = DATASET_DIRECTORIES[field_type]\n",
    "        datafiles.extend([os.path.join(dataset_directory, x) for x in sorted(os.listdir(dataset_directory))])\n",
    "    \n",
    "    jobs = [(datafile, method) for datafile in datafiles]\n",
    "    if parallel_processes == 1:\n",
    "        for job in jobs:\n",
    "            process_clip(job)\n",
    "    else:\n",
    "        pool = multiprocessing.Pool(parallel_processes)\n",
    "        pool.map(process_clip, jobs)\n",
    "        pool.close()\n",
    "        pool.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
